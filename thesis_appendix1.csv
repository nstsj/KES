paper,implementation,idea,architecture,F1,pre-trained models available
CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases,https://github.com/INK-USC/USC-DS-RelationExtraction,extracts entity relation type across named-entity annotated corpus (combines a knowledge base),embedding-based framework with distant supervision,0.369, +
Adversarial training for multi-context joint entity and relation extraction,https://github.com/bekou/multihead_joint_entity_relation_extraction,"Given a sequence of tokens (i.e., sentence), it gives the entity tag of each word (NER) +  the relation extraction between the entities ",NN with attention (все на tensorflow) и кажется выложена не предобученная модель,0.641, +
Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction,https://github.com/nusnlp/PtrNetDecoding4JERE,NER+ relation extraction from text,encoder-decoder,0.844,
Span-based Joint Entity and Relation Extraction with Transformer Pre-training,https://github.com/vedantc6/mtl-dts,"an attention model for span-based joint entity and relation extraction. 
light-weight reasoning on BERT embeddings, which features entity recognition and filtering, as well as relation classification with a localized, marker-free context representation.",transformer with attention,0.866,
GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction,https://github.com/tsujuifu/pytorch_graph-rel,"end-to-end relation extraction model which uses graph convolutional networks (GCNs) to jointly learn named entities and relations. 
we consider the interaction between named entities and relations via a 2nd-phase relation-weighted GCN to better extract relations. ",bi-RNN + GCN + GCN  ,"0.81- 0.91 
for entity recognition
", +
SciERC,https://github.com/dwadden/dygiepp,"multi-task framework for three information extraction tasks: named entity recognition, relation extraction, and event extraction. ",BERT + propagating span representations via predicted coreference links,"0.68 - NER
0.48 - RE", +
SciERC lightweight,,same as previous,,"0.67 NER
0.46 ER", +
GENIA,,same as previous,,0.78 NER, +
GENIA lightweight,,same as previous,,0.76 NER, +
ChemProt,,same as previous,,"0.88 NER
0.35 ER", +
ACE04,https://github.com/luanyi/DyGIE,"a general framework for several information extraction tasks.
The graphs are constructed by selecting the most confident entity spans and linking these nodes with confidence-weighted relation types and coreferences. ",,"0.874- NER
0.597- RE", +
ACE05,,same as previous,,"0.884-NER
0.632-RE", +
SciERC,,same as previous,,"0.652 - NER
0.416 - RE", +
WLPC,,same as previous,,"0.795 - NER
0.641 - RE", +